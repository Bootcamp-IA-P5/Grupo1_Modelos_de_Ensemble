{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EcoPredict - Evaluaci√≥n Completa del Modelo\n",
        "\n",
        "## üìä An√°lisis T√©cnico del Modelo XGBoost Optimizado\n",
        "\n",
        "Este notebook genera todas las m√©tricas t√©cnicas necesarias para la presentaci√≥n:\n",
        "\n",
        "- ‚úÖ **Matriz de confusi√≥n** por clase\n",
        "- ‚úÖ **Precision, Recall, F1** por clase  \n",
        "- ‚úÖ **Feature importance** (SHAP)\n",
        "- ‚úÖ **An√°lisis de errores** del modelo\n",
        "- ‚úÖ **M√©tricas de overfitting** verificadas\n",
        "- ‚úÖ **Visualizaciones** para presentaci√≥n\n",
        "\n",
        "**Modelo**: XGBoost optimizado (97.07% accuracy)  \n",
        "**Dataset**: Forest Cover Type Dataset  \n",
        "**Overfitting**: <5% (0.76%)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar librer√≠as necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, \n",
        "    precision_recall_fscore_support, accuracy_score\n",
        ")\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar estilo de gr√°ficos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üìö Librer√≠as importadas correctamente\")\n",
        "print(\"üé® Estilo de gr√°ficos configurado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar datos y modelo\n",
        "print(\"üìä Cargando Forest Cover Type Dataset...\")\n",
        "covertype = fetch_ucirepo(id=31)\n",
        "X = covertype.data.features\n",
        "y = covertype.data.targets.iloc[:, 0]\n",
        "\n",
        "print(\"ü§ñ Cargando modelo optimizado...\")\n",
        "model = joblib.load('models/best_model.pkl')\n",
        "scaler = joblib.load('models/scaler.pkl')\n",
        "\n",
        "print(f\"‚úÖ Datos cargados: {X.shape[0]:,} muestras, {X.shape[1]} features\")\n",
        "print(f\"‚úÖ Clases: {sorted(y.unique())}\")\n",
        "print(f\"‚úÖ Modelo: {type(model).__name__}\")\n",
        "print(f\"‚úÖ Scaler: {type(scaler).__name__}\")\n",
        "\n",
        "# Nombres de las clases para visualizaci√≥n\n",
        "class_names = {\n",
        "    0: \"Spruce/Fir\",\n",
        "    1: \"Lodgepole Pine\", \n",
        "    2: \"Ponderosa Pine\",\n",
        "    3: \"Cottonwood/Willow\",\n",
        "    4: \"Aspen\",\n",
        "    5: \"Douglas-fir\",\n",
        "    6: \"Krummholz\"\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Clases mapeadas: {len(class_names)} tipos de bosque\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar datos para evaluaci√≥n\n",
        "print(\"üîÑ Preparando datos para evaluaci√≥n...\")\n",
        "\n",
        "# Split de datos (mismo que en entrenamiento)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Escalar datos\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Predicciones\n",
        "print(\"üîÆ Generando predicciones...\")\n",
        "train_pred = model.predict(X_train_scaled)\n",
        "test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Probabilidades (para an√°lisis de confianza)\n",
        "train_proba = model.predict_proba(X_train_scaled)\n",
        "test_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "print(f\"‚úÖ Training set: {X_train.shape[0]:,} muestras\")\n",
        "print(f\"‚úÖ Test set: {X_test.shape[0]:,} muestras\")\n",
        "print(f\"‚úÖ Predicciones generadas\")\n",
        "print(f\"‚úÖ Probabilidades calculadas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà **1. M√©tricas Globales del Modelo**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular m√©tricas globales\n",
        "train_acc = accuracy_score(y_train, train_pred)\n",
        "test_acc = accuracy_score(y_test, test_pred)\n",
        "overfitting = train_acc - test_acc\n",
        "\n",
        "print(\"üéØ M√âTRICAS GLOBALES DEL MODELO\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìä Training Accuracy:  {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
        "print(f\"üìä Test Accuracy:      {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(f\"üìä Overfitting:        {overfitting:.4f} ({overfitting*100:.2f}%)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Verificar que el overfitting es <5%\n",
        "if overfitting < 0.05:\n",
        "    print(\"‚úÖ CUMPLE: Overfitting < 5%\")\n",
        "else:\n",
        "    print(\"‚ùå PROBLEMA: Overfitting >= 5%\")\n",
        "\n",
        "print(f\"\\nüèÜ RESULTADO: Modelo con {test_acc*100:.2f}% de precisi√≥n\")\n",
        "print(f\"üéØ OBJETIVO: {'‚úÖ CUMPLIDO' if test_acc >= 0.97 else '‚ùå NO CUMPLIDO'} (97%+ accuracy)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
