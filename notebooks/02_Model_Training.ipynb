{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenamiento de Modelos de Clasificación Multiclase\n",
        "\n",
        "**Rol 2: Ingeniero/a de Modelos**  \n",
        "**Objetivo**: Entrenar, evaluar y optimizar modelos con overfitting <5%\n",
        "\n",
        "##  Plan de Trabajo\n",
        "\n",
        "### Fase 1: Modelos Base\n",
        "- [ ] Cargar datos del EDA\n",
        "- [ ] Entrenar modelos base: LogisticRegression, DecisionTree, RandomForest\n",
        "- [ ] Calcular métricas iniciales\n",
        "\n",
        "### Fase 2: Optimización\n",
        "- [ ] Validación cruzada (StratifiedKFold)\n",
        "- [ ] Modelos ensemble: XGBoost, LightGBM\n",
        "- [ ] Ajuste de hiperparámetros\n",
        "- [ ] Control de overfitting\n",
        "\n",
        "### Fase 3: Análisis Final\n",
        "- [ ] Métricas por clase\n",
        "- [ ] Análisis de errores\n",
        "- [ ] Exportar modelo final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# Configurar visualizaciones\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\" Librerías importadas correctamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Paso 1: Cargar datos del EDA\n",
        "\n",
        "**IMPORTANTE**: Primero necesitas revisar el notebook `01_EDA.ipynb` para:\n",
        "1. Ver qué dataset tienes\n",
        "2. Identificar las features (X) y el target (y)\n",
        "3. Cargar los datos aquí\n",
        "\n",
        "**Ejemplo de cómo cargar datos:**\n",
        "```python\n",
        "# Si tienes un CSV:\n",
        "datos = pd.read_csv('data/raw/tu_dataset.csv')\n",
        "\n",
        "# Si tienes un archivo procesado del EDA:\n",
        "datos = pd.read_csv('data/processed/datos_limpios.csv')\n",
        "\n",
        "# Separar features y target\n",
        "X = datos.drop('target_column', axis=1)  # todas las columnas excepto la target\n",
        "y = datos['target_column']  # solo la columna target\n",
        "\n",
        "print(f\"Features: {X.shape}\")\n",
        "print(f\"Target: {y.shape}\")\n",
        "print(f\"Clases: {y.unique()}\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CARGAR DATOS DEL FOREST COVER TYPE DATASET\n",
        "# Usando ucimlrepo para descargar directamente desde UCI\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Descargar dataset\n",
        "print(\" Descargando Forest Cover Type Dataset\")\n",
        "covertype = fetch_ucirepo(id=31)\n",
        "\n",
        "# Obtener datos\n",
        "X = covertype.data.features\n",
        "y = covertype.data.targets\n",
        "\n",
        "# Convertir y a serie si es necesario\n",
        "if hasattr(y, 'iloc'):\n",
        "    y = y.iloc[:, 0]  # Tomar la primera columna si es DataFrame\n",
        "\n",
        "print(\"Datos cargados correctamente\")\n",
        "print(f\"   - Features: {X.shape}\")\n",
        "print(f\"   - Target: {y.shape}\")\n",
        "print(f\"   - Clases: {sorted(y.unique())}\")\n",
        "print(f\"   - Distribución de clases:\")\n",
        "print(y.value_counts().sort_index())\n",
        "\n",
        "# Mostrar información del dataset\n",
        "print(f\"\\n Información del dataset:\")\n",
        "print(f\"   - Nombres de features: {list(X.columns)}\")\n",
        "print(f\"   - Tipos de datos: {X.dtypes.value_counts()}\")\n",
        "print(f\"   - Valores nulos: {X.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Paso 2: Comparar modelos (SIMPLE)\n",
        "\n",
        "Una vez que tengas X e y cargados, ejecuta esta celda para comparar todos los modelos de una vez:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar la función de comparación\n",
        "import sys\n",
        "sys.path.append('../src/models')\n",
        "from model_comparison import compare_models\n",
        "\n",
        "# Comparar todos los modelos de una vez\n",
        "print(\"🧠 COMPARANDO MODELOS DE CLASIFICACIÓN MULTICLASE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "resultados = compare_models(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Paso 3: Análisis de resultados\n",
        "\n",
        "Una vez ejecutado el código anterior, aquí puedes analizar los resultados:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
