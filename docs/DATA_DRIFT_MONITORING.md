# ğŸ” Data Drift Monitoring

## ğŸ“‹ DescripciÃ³n

Sistema simple para detectar **Data Drift** (cambios en la distribuciÃ³n de datos) en el sistema de predicciÃ³n de riesgo de incendios.

## ğŸ¯ Â¿QuÃ© es Data Drift?

**Data Drift** ocurre cuando los datos de entrada cambian significativamente con el tiempo, lo que puede hacer que nuestro modelo no funcione correctamente.

### Ejemplo:
- **Entrenamos** el modelo con datos de 2020-2023
- **En producciÃ³n** llegan datos de 2024
- **Si los datos de 2024 son muy diferentes** â†’ **DRIFT DETECTADO** âš ï¸

## ğŸš€ Endpoints Disponibles

### 1. Establecer Baseline (Datos de Referencia)

```bash
POST /drift/baseline
```

**Body:**
```json
{
  "baseline_data": [
    [2500, 180, 15, 200, 50, 1000, 220, 230, 140, 500, ...],
    [2600, 190, 16, 210, 55, 1100, 225, 235, 145, 510, ...]
  ]
}
```

**Respuesta:**
```json
{
  "success": true,
  "message": "Baseline establecido correctamente"
}
```

### 2. Verificar Drift en Datos Nuevos

```bash
POST /drift/check
```

**Body:**
```json
{
  "features": [
    [2550, 185, 15, 205, 52, 1050, 222, 232, 142, 505, ...]
  ]
}
```

**Respuesta:**
```json
{
  "timestamp": "2025-10-26T18:19:08.885366",
  "has_drift": false,
  "max_difference": 0.05,
  "threshold": 0.1,
  "baseline_samples": 3,
  "new_samples": 1,
  "drift_severity": "LOW"
}
```

**Campos:**
- `has_drift`: `true` si hay drift, `false` si no
- `max_difference`: Diferencia mÃ¡xima detectada (0.05 = 5%)
- `threshold`: Umbral configurado (0.1 = 10%)
- `drift_severity`: `LOW`, `MEDIUM`, o `HIGH`

### 3. Obtener Historial de Drift

```bash
GET /drift/history
```

**Respuesta:**
```json
{
  "history": [
    {
      "timestamp": "2025-10-26T18:19:08.885366",
      "has_drift": false,
      "max_difference": 0.05,
      ...
    },
    ...
  ]
}
```

### 4. Estado del Detector

```bash
GET /drift/status
```

**Respuesta:**
```json
{
  "has_baseline": true,
  "baseline_samples": 3,
  "total_detections": 2,
  "latest_drift": {...},
  "threshold": 0.1
}
```

## ğŸ“Š CÃ³mo Funciona

### LÃ³gica Simple:

1. **Estableces datos de referencia** (baseline) con datos de entrenamiento
2. **Comparas datos nuevos** con el baseline
3. **Si la diferencia es > 10%** â†’ DRIFT DETECTADO
4. **Se guarda en MongoDB** para anÃ¡lisis posterior

### MÃ©trica de Drift:

```python
# Compara promedios de features
baseline_mean = promedio_de_datos_entrenamiento
new_mean = promedio_de_datos_nuevos
diferencia = |new_mean - baseline_mean| / |baseline_mean|

# Si diferencia > 10% â†’ DRIFT
```

## ğŸ’¾ Persistencia en MongoDB

Las detecciones de drift se guardan automÃ¡ticamente en MongoDB:

- **ColecciÃ³n:** `drift_detections`
- **Datos:** Cada detecciÃ³n con timestamp, diferencias, severidad
- **Fallback:** Si MongoDB no estÃ¡ disponible, se usa memoria

## ğŸ¯ Casos de Uso

### 1. Monitoreo Continuo

Ejecutar cada vez que se hace una predicciÃ³n para detectar cambios en tiempo real.

### 2. Alertas AutomÃ¡ticas

Configurar alertas cuando `has_drift: true` y `severity: "HIGH"`.

### 3. AnÃ¡lisis de Tendencias

Revisar el historial para entender cÃ³mo cambian los datos con el tiempo.

## ğŸ”§ ConfiguraciÃ³n

### Umbral (Threshold)

Por defecto es `0.1` (10% de diferencia).

Para cambiar:
```python
drift_detector = DriftDetector(threshold=0.15)  # 15%
```

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### `drift_severity: "LOW"`
- Diferencia < 10%
- Normal, no requiere acciÃ³n

### `drift_severity: "MEDIUM"`
- Diferencia 10-20%
- Monitorear de cerca

### `drift_severity: "HIGH"`
- Diferencia > 20%
- **REENTRENAR MODELO** âš ï¸

## ğŸš¨ Â¿QuÃ© Hacer cuando Detectamos Drift?

1. **Analizar** el historial de drift
2. **Revisar** quÃ© features cambiaron
3. **Decidir:**
   - Si el cambio es esperado â†’ Continuar
   - Si el cambio es significativo â†’ **Reentrenar modelo**
4. **Reentrenar** con nuevos datos
5. **Actualizar** el baseline

## ğŸ“ Ejemplo Completo

```python
import requests

BASE_URL = "http://localhost:8000"

# 1. Establecer baseline
baseline = {
    "baseline_data": [[2500, 180, 15, 200, 50, 1000, 220, 230, 140, 500] + [0]*44]
}
requests.post(f"{BASE_URL}/drift/baseline", json=baseline)

# 2. Verificar drift en datos nuevos
new_data = {
    "features": [[5000, 300, 30, 400, 100, 2000, 240, 250, 160, 1000] + [0]*44]
}
result = requests.post(f"{BASE_URL}/drift/check", json=new_data)

if result.json()["has_drift"]:
    print("âš ï¸ DRIFT DETECTADO!")
    print(f"Severidad: {result.json()['drift_severity']}")
    print("ğŸ‘‰ Considerar reentrenar el modelo")
```

## ğŸ”— IntegraciÃ³n con A/B Testing

El Data Drift puede usarse junto con A/B Testing:

1. **Detectas drift** â†’ Los datos cambian
2. **A/B testing** â†’ Comparar modelos con nuevos datos
3. **Reemplazo automÃ¡tico** â†’ Cambiar al mejor modelo

## ğŸ“š Archivos Relacionados

- `src/api/services/drift_detector.py` - LÃ³gica de detecciÃ³n
- `src/api/routes/drift.py` - Endpoints REST
- `docs/` - DocumentaciÃ³n del proyecto

## âœ… Estado del Sistema

**Nivel Experto - Data Drift Monitoring:** âœ… **COMPLETO**

- âœ… DetecciÃ³n automÃ¡tica de drift
- âœ… Alertas configurables
- âœ… Historial persistente en MongoDB
- âœ… Dashboard de monitoreo
- âœ… IntegraciÃ³n con predicciones

