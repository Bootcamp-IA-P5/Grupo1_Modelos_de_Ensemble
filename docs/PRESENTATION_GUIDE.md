# üìã Gu√≠a de Presentaci√≥n - FireRiskAI Dashboard

## üéØ Objetivo

Esta gu√≠a explica c√≥mo presentar las funcionalidades avanzadas del proyecto (A/B Testing, Data Drift y Auto Model Replacement) durante la demostraci√≥n.

## üöÄ C√≥mo Iniciar el Dashboard

### **1. Iniciar el Backend**

```bash
python -m uvicorn app:app --host 0.0.0.0 --port 8000
```

### **2. Iniciar Streamlit Dashboard**

```bash
streamlit run streamlit_dashboard.py
```

El dashboard estar√° disponible en: `http://localhost:8501`

## üìä P√°ginas del Dashboard

### **P√°gina Principal: Inicio**
- T√≠tulo del proyecto y descripci√≥n
- Problem√°tica y soluci√≥n
- Informaci√≥n del dataset
- M√©tricas clave del modelo
- Estado del sistema

### **Predicci√≥n**
- Formulario para introducir features
- Bot√≥n de predicci√≥n
- Resultado con confianza y nivel de riesgo
- Sistema de feedback (thumbs up/down)

### **EDA (An√°lisis Exploratorio)**
- Distribuci√≥n de clases
- Histogramas de features importantes
- Matriz de correlaci√≥n
- Box plots comparativos
- An√°lisis de outliers
- Estad√≠sticas descriptivas

### **Modelo**
- Informaci√≥n detallada del modelo
- M√©tricas por clase
- Feature Importance
- Matriz de Confusi√≥n interactiva
- Configuraci√≥n e hiperpar√°metros
- Comparaci√≥n Train vs Validation

### **Reentrenamiento**
- Contador de datos nuevos recolectados
- An√°lisis de calidad de datos
- Comparaci√≥n modelo actual vs esperado
- Bot√≥n para lanzar reentrenamiento

### **üß™ A/B Testing** ‚≠ê
- Distribuci√≥n de tr√°fico entre modelos
- Estad√≠sticas de rendimiento por modelo
- Visualizaci√≥n de predicciones acumuladas
- Opci√≥n para cambiar pesos de distribuci√≥n

### **üîç Data Drift** ‚≠ê
- Estado del baseline
- Historial de detecciones
- Alertas activas
- Bot√≥n para establecer baseline

### **ü§ñ Gesti√≥n de Modelos** ‚≠ê
- Comparaci√≥n autom√°tica de modelos
- Recomendaci√≥n de reemplazo
- Bot√≥n para activar modelo mejor
- Reemplazo manual si es necesario

### **Documentaci√≥n T√©cnica**
- Pipeline de preprocesamiento
- Arquitectura del modelo
- Gu√≠as de uso de la API

### **Acerca del Proyecto**
- Equipo de desarrollo
- Objetivos del proyecto
- Enlaces (GitHub, Trello)
- Contacto

## üé¨ Gui√≥n de Presentaci√≥n (10-15 minutos)

### **1. Introducci√≥n (2 min)**
- Ir a **Inicio**
- Mostrar t√≠tulo y descripci√≥n del proyecto
- Explicar el problema: clasificar 7 tipos de vegetaci√≥n forestal
- Mostrar m√©tricas principales: 97% accuracy

### **2. Predicci√≥n (2 min)**
- Ir a **Predicci√≥n**
- Mostrar formulario con features topogr√°ficas
- Hacer una predicci√≥n en tiempo real
- Explicar resultado: clase, confianza, nivel de riesgo

### **3. EDA y An√°lisis (2 min)**
- Ir a **EDA**
- Mostrar distribuci√≥n de clases
- Explicar dataset balanceado/desbalanceado
- Mostrar importancia de features

### **4. A/B Testing (3 min)** ‚≠ê **DESTACAR**
- Ir a **A/B Testing**
- Explicar: "Estamos comparando 3 modelos en producci√≥n"
- Mostrar distribuci√≥n de tr√°fico: 33% para cada uno
- Mostrar estad√≠sticas acumuladas
- **Acci√≥n**: Cambiar pesos a XGBoost 70%, RF 15%, ET 15%
- Explicar: "Esto permite comparar rendimiento en producci√≥n real"

### **5. Data Drift Monitoring (2 min)** ‚≠ê **DESTACAR**
- Ir a **Data Drift**
- Explicar: "Detecta cuando los datos cambian significativamente"
- Establecer baseline si no est√° establecido
- Mostrar alertas si hay drift detectado
- Explicar: "Si hay drift, el modelo puede no funcionar bien"

### **6. Auto Model Replacement (2 min)** ‚≠ê **DESTACAR**
- Ir a **Gesti√≥n de Modelos**
- Mostrar comparaci√≥n de modelos
- Explicar: "Sistema compara autom√°ticamente y recomienda"
- Mostrar m√©tricas: Accuracy, F1-Score, Overfitting
- Si hay mejor modelo, mostrar recomendaci√≥n
- **Acci√≥n**: Hacer clic en "Reemplazar" (si aplica)
- Explicar: "Esto asegura que siempre usamos el mejor modelo"

### **7. Resumen (1 min)**
- Ir a **Acerca del Proyecto**
- Mostrar stack tecnol√≥gico
- Mostrar estado del proyecto
- Enlaces al repositorio

## üéØ Puntos Clave para Destacar

### **1. A/B Testing**
- ‚úÖ Permite comparar modelos en producci√≥n real
- ‚úÖ Distribuci√≥n configurable de tr√°fico
- ‚úÖ Estad√≠sticas en tiempo real
- ‚úÖ √ötil para decidir qu√© modelo usar

### **2. Data Drift Monitoring**
- ‚úÖ Detecta cambios en la distribuci√≥n de datos
- ‚úÖ Alertas autom√°ticas
- ‚úÖ Historial de detecciones
- ‚úÖ Permite reentrenar cuando sea necesario

### **3. Auto Model Replacement**
- ‚úÖ Comparaci√≥n autom√°tica de modelos
- ‚úÖ Recomendaci√≥n inteligente
- ‚úÖ Reemplazo con un clic
- ‚úÖ Garantiza mejor rendimiento

## üí° Tips para la Presentaci√≥n

1. **Demonstraci√≥n en vivo**: Hacer predicciones reales durante la presentaci√≥n
2. **Navegar fluidamente**: Mostrar transiciones entre p√°ginas
3. **Destacar MLOps**: A/B Testing, Data Drift y Auto Replacement son claves
4. **Interactividad**: Usar botones y gr√°ficos interactivos
5. **Backend activo**: Asegurar que el backend est√© corriendo

## üîß Problemas Comunes

### **Backend no responde**
```bash
# Verificar que est√° corriendo
curl http://localhost:8000/health
```

### **Dashboard no carga**
```bash
# Reiniciar Streamlit
streamlit run streamlit_dashboard.py --server.port 8501
```

### **Modelos no encontrados**
- Verificar que existen archivos en `models/`:
  - `best_model.pkl`
  - `scaler.pkl`
  - `metadata.json`

## üìù Notas Finales

- Todas las funcionalidades est√°n implementadas y funcionando
- El dashboard es interactivo y permite demostraci√≥n en tiempo real
- Se puede conectar a MongoDB en producci√≥n para datos reales
- Los modelos est√°n entrenados y optimizados
- Backend desplegado en Render.com
- C√≥digo disponible en GitHub

---

**¬© 2025 Grupo 1 - FireRiskAI**

